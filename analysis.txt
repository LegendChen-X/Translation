---------RNN---------
Model Without Attention:
Epoch 1: loss=3.2204901951351017, BLEU=0.24652812139383576
Epoch 2: loss=2.4677056588647774, BLEU=0.25452834858706
Epoch 3: loss=2.121018988039569, BLEU=0.25530642745832277
Epoch 4: loss=1.8965539850984394, BLEU=0.2609218178985958
Epoch 5: loss=1.7533158586081246, BLEU=0.26076047405929176

The average BLEU score over the test set was 0.30268162114292074

Model With Attention:
Epoch 1: loss=3.245269063429479, BLEU=0.2652796550551756
Epoch 2: loss=2.414064955952968, BLEU=0.276769320724109
Epoch 3: loss=2.1121078485280673, BLEU=0.2869184557556558
Epoch 4: loss=1.926685931934074, BLEU=0.28674835427887796
Epoch 5: loss=1.8066448114918763, BLEU=0.288871066032453

The average BLEU score over the test set was 0.34238250003166226

Model With Multi-Head Attention:
Epoch 1: loss=3.5002306550947107, BLEU=0.24964149984291475
Epoch 2: loss=2.65075776600058, BLEU=0.26199573457997727
Epoch 3: loss=2.408818768774074, BLEU=0.26630957297935076
Epoch 4: loss=2.275109892394454, BLEU=0.2698288042934561
Epoch 5: loss=2.1893063596403035, BLEU=0.26880023730349983

The average BLEU score over the test set was 0.3279013388091001

---------GRU---------
Model Without Attention:
Epoch 1: loss=3.4494064499957395, BLEU=0.2396173104554013
Epoch 2: loss=2.762618427285397, BLEU=0.2543609880092988
Epoch 3: loss=2.5254896890727236, BLEU=0.25795454928509426
Epoch 4: loss=2.392259253383726, BLEU=0.25930659927347066
Epoch 5: loss=2.3122200818173844, BLEU=0.25820768344552786

The average BLEU score over the test set was 0.3016709989061593

Model With Attention:
Epoch 1: loss=2.8546301912789187, BLEU=0.2909509260758202
Epoch 2: loss=1.943022662349035, BLEU=0.3093467545915857
Epoch 3: loss=1.556847063477058, BLEU=0.31176220554280787
Epoch 4: loss=1.3353139669979732, BLEU=0.3134113052917401
Epoch 5: loss=1.2026123186510755, BLEU=0.3145409176635263

The average BLEU score over the test set was 0.3609300088313765

Model With Multi-Head Attention:
Epoch 1: loss=3.3136787551825413, BLEU=0.27303796395278906
Epoch 2: loss=2.2617031627951105, BLEU=0.2918940827230101
Epoch 3: loss=1.908441618146681, BLEU=0.30057310121502934
Epoch 4: loss=1.6955352486250643, BLEU=0.30414916215128684
Epoch 5: loss=1.5577980864163314, BLEU=0.30642043957196385

The average BLEU score over the test set was 0.35661583382903195

---------LSTM---------
Model Without Attention:
Epoch 1: loss=3.4528882840656014, BLEU=0.22547948037893917
Epoch 2: loss=2.5150256978921877, BLEU=0.2576845494804469
Epoch 3: loss=2.0625583674159813, BLEU=0.26939737460212676
Epoch 4: loss=1.716922990082047, BLEU=0.2792566968527238
Epoch 5: loss=1.4472787078214318, BLEU=0.284886270657056

The average BLEU score over the test set was 0.3188164434816782

Model With Attention:
Epoch 1: loss=3.1882800793439108, BLEU=0.276711837866153
Epoch 2: loss=2.1353699621216378, BLEU=0.3041657843022162
Epoch 3: loss=1.6675646100270478, BLEU=0.31596796198940236
Epoch 4: loss=1.3363359142206386, BLEU=0.3245141223019426
Epoch 5: loss=1.0951582593942006, BLEU=0.3246859545289152

The average BLEU score over the test set was 0.36453155411409205

Model With Multi-Head Attention:
Epoch 1: loss=3.1686258060709225, BLEU=0.2753695382851852
Epoch 2: loss=2.167683377621746, BLEU=0.3044090934076387
Epoch 3: loss=1.753824691956958, BLEU=0.3157075192499359
Epoch 4: loss=1.4680893727020974, BLEU=0.3213482674460742
Epoch 5: loss=1.259561816238138, BLEU=0.3268259529350511

The average BLEU score over the test set was 0.37205276790566444

------------------------------------------------------------------------------------------

According to what we have above, we can see our models actually have a better performance on test set compared with training set. It is uncommon. I have several explanations for this phenomena. First, it may because the test set is much easier than training set. We can also expect that our model actually does not have overfit problem since it has a positive reaction to unseen data. We can see both versions of attention models have better performance than the normal one and this is in our expectation since the model looks through the whole sequence instead of only local features. 